{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)} # String to Int\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()} # Int to String\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# . . . e --- m \n",
    "# . . e m --- m \n",
    "# . e m m --- a\n",
    "# e m m a --- . "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating context and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def build_dataset(words, block_size):\n",
    "    \"\"\"\n",
    "    Build a dataset of the words using the block size of characters as the\n",
    "    samples and the next character as the label.\n",
    "    \"\"\"\n",
    "\n",
    "    # context length of characters taken to predict the next \n",
    "    X, Y = [],[]\n",
    "\n",
    "    for w in words:\n",
    "        \n",
    "        #print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print(''.join(itos[i] for i in context), '------>', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "def get_loss(c, xs, ys, nembs, block_size, w1, b1, w2, b2):\n",
    "    emb = c[xs]\n",
    "    h = torch.tanh(emb.view(-1, nembs*block_size) @ w1 + b1)\n",
    "    logits = h @ w2 + b2\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "    return loss\n",
    "\n",
    "def generate_names(c, n_names:int, block_size, w1, b1, w2, b2, g):\n",
    "    out = []\n",
    "    for _ in range(n_names):\n",
    "        name = []\n",
    "        \n",
    "        context = [0] * block_size\n",
    "        while True:\n",
    "            emb = c[torch.tensor([context])]\n",
    "            h = torch.tanh(emb.view(1, -1) @ w1 + b1)\n",
    "            logits = h @ w2 + b2\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "            context = context[1:] + [ix]\n",
    "            name.append(ix)\n",
    "            if ix == 0:\n",
    "                break\n",
    "        \n",
    "\n",
    "        out.append(name)\n",
    "    \n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making it more respecatble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# EMB = 30\n",
    "# BLOCK_SIZE = 3\n",
    "# BATCH_SIZE = 32\n",
    "# EPOCHS = 20000\n",
    "\n",
    "# random.seed(42)\n",
    "# random.shuffle(words)\n",
    "# n1 = int(0.8*len(words))\n",
    "# n2 = int(0.9*len(words)) \n",
    "# Xtrain, Ytrain = build_dataset(words[:n1], BLOCK_SIZE)\n",
    "# Xdev, Ydev = build_dataset(words[n1:n2], BLOCK_SIZE)\n",
    "# Xtest, Ytest = build_dataset(words[n2:], BLOCK_SIZE)\n",
    "\n",
    "# g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# c = torch.randn((27, EMB), generator=g)\n",
    "# w1 = torch.randn((BLOCK_SIZE*EMB, 200), generator=g)\n",
    "# b1 = torch.randn((200), generator=g)\n",
    "# w2 = torch.randn((200, 27), generator=g)\n",
    "# b2 = torch.randn((27), generator=g)\n",
    "\n",
    "# parameters = [c, w1, b1, w2, b2]\n",
    "# nparameters = sum(p.nelement() for p in parameters)\n",
    "# print(nparameters)\n",
    "\n",
    "# for p in parameters:\n",
    "#     p.requires_grad = True\n",
    "\n",
    "\n",
    "# for i in range(EPOCHS):\n",
    "#     # minibatch construct\n",
    "#     ix = torch.randint(0, Xtrain.shape[0], (BATCH_SIZE,))\n",
    "#     # forward pass\n",
    "#     emb = c[Xtrain[ix]]\n",
    "#     h = torch.tanh(emb.view(-1, BLOCK_SIZE*EMB) @ w1 + b1)\n",
    "#     logits = h @ w2 + b2\n",
    "#     loss = F.cross_entropy(logits, Ytrain[ix])\n",
    "#     # backward pass\n",
    "#     for p in parameters:\n",
    "#         p.grad = None\n",
    "#     loss.backward()\n",
    "#     # update\n",
    "#     lr = 0.01 if i < EPOCHS//2 else 0.01\n",
    "#     for p in parameters:\n",
    "#         p.data += -lr  * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# g = torch.Generator().manual_seed(2147483647+ 10) \n",
    "# names = generate_names(c, 10, BLOCK_SIZE, w1, b1, w2, b2, g)\n",
    "\n",
    "# for name in names:\n",
    "#     print(''.join(itos[i] for i in name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of number of embeddings on training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# lossi = []\n",
    "\n",
    "# n_embs = [x+1 for x in range(30)]\n",
    "# n_steps = EPOCHS\n",
    "\n",
    "# for n_emb in n_embs:\n",
    "\n",
    "#     g = torch.Generator().manual_seed(2147483647)\n",
    "#     c = torch.randn((27, n_emb), generator=g)\n",
    "#     w1 = torch.randn((n_emb * BLOCK_SIZE, 200), generator=g)\n",
    "#     b1 = torch.randn((200), generator=g)\n",
    "#     w2 = torch.randn((200, 27), generator=g)\n",
    "#     b2 = torch.randn((27), generator=g)\n",
    "\n",
    "#     parameters = [c, w1, b1, w2, b2]\n",
    "#     nparameters = sum(p.nelement() for p in parameters)\n",
    "#     print('-------')\n",
    "#     print(f'{nparameters=}')\n",
    "#     print(f\"{n_emb} embeddings\")\n",
    "#     print('-------')\n",
    "\n",
    "#     for p in parameters:\n",
    "#         p.requires_grad = True\n",
    "\n",
    "#     losses = []\n",
    "#     avg_loss = 0\n",
    "#     temp_loss = 0\n",
    "#     for i in range(EPOCHS + 1):\n",
    "#         # minibatch construct\n",
    "#         ix = torch.randint(0, Xdev.shape[0], (BATCH_SIZE,))\n",
    "#         # forward pass\n",
    "#         emb = c[Xdev[ix]]\n",
    "#         h = torch.tanh(emb.view(-1, BLOCK_SIZE*n_emb) @ w1 + b1)\n",
    "#         logits = h @ w2 + b2\n",
    "#         loss = F.cross_entropy(logits, Ydev[ix])\n",
    "#         # backward pass\n",
    "#         for p in parameters:\n",
    "#             p.grad = None\n",
    "#         loss.backward()\n",
    "#         # update\n",
    "#         lr = 0.01 if i < EPOCHS//2 else 0.01\n",
    "#         for p in parameters:\n",
    "#             p.data += -lr  * p.grad\n",
    "#         # track stats\n",
    "\n",
    "#         temp_loss += loss.item()\n",
    "\n",
    "#         if i%(EPOCHS//10) == 0:\n",
    "#             print(f\"Epochs: {i}\")\n",
    "            \n",
    "#             if i != 0:\n",
    "#                 avg_loss = temp_loss/(EPOCHS//10)\n",
    "#                 print(avg_loss)\n",
    "#                 losses.append(avg_loss)\n",
    "\n",
    "#             temp_loss = 0\n",
    "            \n",
    "#             #print(f\"{loss.item()}\")\n",
    "\n",
    "        \n",
    "#     lossi.append(min(losses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 or 5 seems like a good number here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# EMB = 4\n",
    "# BLOCK_SIZE = 3\n",
    "# BATCH_SIZE = 32\n",
    "# EPOCHS = 100000\n",
    "\n",
    "# dev_loss = []\n",
    "# test_loss = []\n",
    "# hidden_layer_lengths = [10 * (x + 20) for x in range(10)]\n",
    "\n",
    "# for hidden_layer_length in hidden_layer_lengths:\n",
    "\n",
    "#     g = torch.Generator().manual_seed(2147483647)\n",
    "#     c = torch.randn((27, EMB), generator=g)\n",
    "#     w1 = torch.randn((EMB * BLOCK_SIZE, hidden_layer_length), generator=g)\n",
    "#     b1 = torch.randn((hidden_layer_length), generator=g)\n",
    "#     w2 = torch.randn((hidden_layer_length, 27), generator=g)\n",
    "#     b2 = torch.randn((27), generator=g)\n",
    "\n",
    "#     parameters = [c, w1, b1, w2, b2]\n",
    "#     nparameters = sum(p.nelement() for p in parameters)\n",
    "#     print('-------')\n",
    "#     print(f'{nparameters=}')\n",
    "#     print(f'{hidden_layer_length=}')\n",
    "#     print('-------')\n",
    "\n",
    "#     for p in parameters:\n",
    "#         p.requires_grad = True\n",
    "\n",
    "#     dev_lossi = []\n",
    "#     dev_loss_avg = 0\n",
    "#     dev_loss_temp = 0\n",
    "\n",
    "#     test_lossi = []\n",
    "#     test_loss_avg = 0\n",
    "#     test_loss_temp = 0\n",
    "\n",
    "#     for i in range(EPOCHS + 1):\n",
    "#         # minibatch construct\n",
    "#         ix = torch.randint(0, Xdev.shape[0], (BATCH_SIZE,))\n",
    "#         # forward pass\n",
    "#         emb = c[Xdev[ix]]\n",
    "#         h = torch.tanh(emb.view(-1, BLOCK_SIZE*EMB) @ w1 + b1)\n",
    "#         logits = h @ w2 + b2\n",
    "#         loss = F.cross_entropy(logits, Ydev[ix])\n",
    "#         # backward pass\n",
    "#         for p in parameters:\n",
    "#             p.grad = None\n",
    "#         loss.backward()\n",
    "#         # update\n",
    "#         lr = 0.1 if i < EPOCHS//2 else 0.01\n",
    "#         for p in parameters:\n",
    "#             p.data += -lr  * p.grad\n",
    "#         # track stats\n",
    "\n",
    "#         dev_loss_temp += loss.item()\n",
    "\n",
    "#         test_loss_temp += get_loss(c, Xtest, Ytest, EMB, BLOCK_SIZE, w1, b1, w2, b2).item()\n",
    "\n",
    "#         if i%(EPOCHS//10) == 0:\n",
    "#             print(f\"Epochs: {i}\")\n",
    "\n",
    "#             if i != 0:\n",
    "#                 dev_loss_avg = dev_loss_temp/(EPOCHS//10)\n",
    "#                 print(f\"Average dev loss: {dev_loss_avg:.6f}\")\n",
    "#                 dev_lossi.append(dev_loss_avg)\n",
    "\n",
    "#                 test_loss_avg = test_loss_temp/(EPOCHS//10)\n",
    "#                 print(f'Average test loss: {test_loss_avg:.6f}')\n",
    "#                 test_lossi.append(test_loss_avg)\n",
    "\n",
    "#             dev_loss_temp = 0\n",
    "#             test_loss_temp = 0\n",
    "\n",
    "#     dev_loss.append(min(dev_lossi))\n",
    "#     test_loss.append(min(test_lossi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# #plt.plot(step, test_loss)\n",
    "# plt.plot(step, dev_loss)\n",
    "# plt.legend(['test_loss', 'dev_loss'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 200 to 250 seemed good on the first pass. 260 ended up being the best when doing a more finely spaced analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# EMB = 4\n",
    "# BLOCK_SIZE = 3\n",
    "# HIDDEN_LAYER_LENGTH = 260\n",
    "# EPOCHS = 10000\n",
    "\n",
    "# dev_loss = []\n",
    "# test_loss = []\n",
    "# batch_sizes = [2**(x+3) for x in range(10)] \n",
    "\n",
    "\n",
    "# for batch_size in batch_sizes:\n",
    "\n",
    "#     g = torch.Generator().manual_seed(2147483647)\n",
    "#     c = torch.randn((27, EMB), generator=g)\n",
    "#     w1 = torch.randn((EMB * BLOCK_SIZE, HIDDEN_LAYER_LENGTH), generator=g)\n",
    "#     b1 = torch.randn((HIDDEN_LAYER_LENGTH), generator=g)\n",
    "#     w2 = torch.randn((HIDDEN_LAYER_LENGTH, 27), generator=g)\n",
    "#     b2 = torch.randn((27), generator=g)\n",
    "\n",
    "#     parameters = [c, w1, b1, w2, b2]\n",
    "#     nparameters = sum(p.nelement() for p in parameters)\n",
    "#     print(f'{nparameters} parameters')\n",
    "#     print(f'Batch size: {batch_size}')\n",
    "#     print(f'--------')\n",
    "\n",
    "#     for p in parameters:\n",
    "#         p.requires_grad = True\n",
    "\n",
    "#     dev_lossi = []\n",
    "#     dev_loss_avg = 0\n",
    "#     dev_loss_temp = 0\n",
    "\n",
    "#     test_lossi = []\n",
    "#     test_loss_avg = 0\n",
    "#     test_loss_temp = 0\n",
    "\n",
    "#     for i in range(EPOCHS + 1):\n",
    "#         # minibatch construct\n",
    "#         ix = torch.randint(0, Xdev.shape[0], (batch_size,))\n",
    "#         # forward pass\n",
    "#         emb = c[Xdev[ix]]\n",
    "#         h = torch.tanh(emb.view(-1, BLOCK_SIZE*EMB) @ w1 + b1)\n",
    "#         logits = h @ w2 + b2\n",
    "#         loss = F.cross_entropy(logits, Ydev[ix])\n",
    "#         # backward pass\n",
    "#         for p in parameters:\n",
    "#             p.grad = None\n",
    "#         loss.backward()\n",
    "#         # update\n",
    "#         lr = 0.1 if i < EPOCHS//2 else 0.01\n",
    "#         for p in parameters:\n",
    "#             p.data += -lr  * p.grad\n",
    "#         # track stats\n",
    "#         dev_loss_temp += loss.item()\n",
    "#         test_loss_temp += get_loss(c, Xtest, Ytest, EMB, BLOCK_SIZE, w1, b1, w2, b2).item()\n",
    "\n",
    "\n",
    "#         if i%(EPOCHS//10) == 0:\n",
    "#             print(f\"Epochs: {i}\")\n",
    "\n",
    "            \n",
    "\n",
    "#             if i != 0:\n",
    "#                 dev_loss_avg = dev_loss_temp/(EPOCHS//10)\n",
    "#                 print(f\"Average dev loss: {dev_loss_avg:.6f}\")\n",
    "#                 dev_lossi.append(dev_loss_avg)\n",
    "\n",
    "#                 test_loss_avg = test_loss_temp/(EPOCHS//10)\n",
    "#                 print(f'Average test loss: {test_loss_avg:.6f}')\n",
    "#                 test_lossi.append(test_loss_avg)\n",
    "#             else:\n",
    "#                 print(f'Starting dev loss: {dev_loss_temp:.6f}')\n",
    "#                 print(f'Starting test loss: {test_loss_temp:.6f}')\n",
    "\n",
    "#             dev_loss_temp = 0\n",
    "#             test_loss_temp = 0\n",
    "\n",
    "#     dev_loss.append(min(dev_lossi))\n",
    "#     test_loss.append(min(test_lossi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# plt.plot(batch_sizes, test_loss)\n",
    "# plt.plot(batch_sizes, dev_loss)\n",
    "# plt.legend(['test_loss', 'dev_loss'])\n",
    "# plt.xscale('log')\n",
    "# plt.xticks(batch_sizes, batch_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch size of 64 seems to be a good value here. Moving on to block size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# EMB = 4\n",
    "# BATCH_SIZE = 64\n",
    "# BLOCK_SIZE = 4\n",
    "# HIDDEN_LAYER_LENGTH = 260\n",
    "# EPOCHS = 10000\n",
    "\n",
    "# dev_loss = []\n",
    "# test_loss = []\n",
    "# block_sizes = [x for x in range(2, 7)]\n",
    "\n",
    "# for block_size in block_sizes:\n",
    "\n",
    "#     random.seed(42)\n",
    "#     random.shuffle(words)\n",
    "#     n1 = int(0.8*len(words))\n",
    "#     n2 = int(0.9*len(words)) \n",
    "#     Xtrain, Ytrain = build_dataset(words[:n1], block_size)\n",
    "#     Xdev, Ydev = build_dataset(words[n1:n2], block_size)\n",
    "#     Xtest, Ytest = build_dataset(words[n2:], block_size)\n",
    "\n",
    "#     g = torch.Generator().manual_seed(2147483647)\n",
    "#     c = torch.randn((27, EMB), generator=g)\n",
    "#     w1 = torch.randn((EMB * block_size, HIDDEN_LAYER_LENGTH), generator=g)\n",
    "#     b1 = torch.randn((HIDDEN_LAYER_LENGTH), generator=g)\n",
    "#     w2 = torch.randn((HIDDEN_LAYER_LENGTH, 27), generator=g)\n",
    "#     b2 = torch.randn((27), generator=g)\n",
    "\n",
    "#     parameters = [c, w1, b1, w2, b2]\n",
    "#     nparameters = sum(p.nelement() for p in parameters)\n",
    "#     print(f'{nparameters} parameters')\n",
    "#     print(f'Block size: {block_size}')\n",
    "#     print(f'--------')\n",
    "\n",
    "#     for p in parameters:\n",
    "#         p.requires_grad = True\n",
    "\n",
    "#     dev_lossi = []\n",
    "#     dev_loss_avg = 0\n",
    "#     dev_loss_temp = 0\n",
    "\n",
    "#     test_lossi = []\n",
    "#     test_loss_avg = 0\n",
    "#     test_loss_temp = 0\n",
    "\n",
    "#     for i in range(EPOCHS + 1):\n",
    "#         # minibatch construct\n",
    "#         ix = torch.randint(0, Xdev.shape[0], (BATCH_SIZE,))\n",
    "#         # forward pass\n",
    "#         emb = c[Xdev[ix]]\n",
    "#         h = torch.tanh(emb.view(-1, block_size*EMB) @ w1 + b1)\n",
    "#         logits = h @ w2 + b2\n",
    "#         loss = F.cross_entropy(logits, Ydev[ix])\n",
    "#         # backward pass\n",
    "#         for p in parameters:\n",
    "#             p.grad = None\n",
    "#         loss.backward()\n",
    "#         # update\n",
    "#         lr = 0.1 if i < EPOCHS//2 else 0.01\n",
    "#         for p in parameters:\n",
    "#             p.data += -lr  * p.grad\n",
    "#         # track stats\n",
    "#         dev_loss_temp += loss.item()\n",
    "#         test_loss_temp += get_loss(c, Xtest, Ytest, EMB, block_size, w1, b1, w2, b2).item()\n",
    "\n",
    "\n",
    "#         if i%(EPOCHS//10) == 0:\n",
    "#             print(f\"Epochs: {i}\")\n",
    "\n",
    "            \n",
    "\n",
    "#             if i != 0:\n",
    "#                 dev_loss_avg = dev_loss_temp/(EPOCHS//10)\n",
    "#                 print(f\"Average dev loss: {dev_loss_avg:.6f}\")\n",
    "#                 dev_lossi.append(dev_loss_avg)\n",
    "\n",
    "#                 test_loss_avg = test_loss_temp/(EPOCHS//10)\n",
    "#                 print(f'Average test loss: {test_loss_avg:.6f}')\n",
    "#                 test_lossi.append(test_loss_avg)\n",
    "#             else:\n",
    "#                 print(f'Starting dev loss: {dev_loss_temp:.6f}')\n",
    "#                 print(f'Starting test loss: {test_loss_temp:.6f}')\n",
    "\n",
    "#             dev_loss_temp = 0\n",
    "#             test_loss_temp = 0\n",
    "\n",
    "#     dev_loss.append(min(dev_lossi))\n",
    "#     test_loss.append(min(test_lossi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# plt.plot(block_sizes, test_loss)\n",
    "# plt.plot(block_sizes, dev_loss)\n",
    "# plt.legend(['test_loss', 'dev_loss'])\n",
    "# plt.xticks(block_sizes, block_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 seems to be the best here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ive increased the batch size in proportion to the size of the training set compared with the dev set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything has been messed with since i ran the experments to try optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "EMB = 60\n",
    "BATCH_SIZE = 512\n",
    "BLOCK_SIZE = 5\n",
    "HIDDEN_LAYER_LENGTH = 50\n",
    "EPOCHS = 100000\n",
    "EVAL_INTERVAL = EPOCHS//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words)) \n",
    "Xtrain, Ytrain = build_dataset(words[:n1], BLOCK_SIZE)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2], BLOCK_SIZE)\n",
    "Xtest, Ytest = build_dataset(words[n2:], BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "c = torch.randn((27, EMB), generator=g)\n",
    "w1 = torch.randn((EMB * BLOCK_SIZE, HIDDEN_LAYER_LENGTH), generator=g)\n",
    "b1 = torch.randn((1,HIDDEN_LAYER_LENGTH), generator=g)\n",
    "w2 = torch.randn((HIDDEN_LAYER_LENGTH, 27), generator=g)\n",
    "b2 = torch.randn((1,27), generator=g)\n",
    "\n",
    "\n",
    "# c1 = torch.full((27, 1), 0.25)\n",
    "# c2 = torch.full((27, 1), 0.50)\n",
    "# c3 = torch.full((27, 1), 0.75)\n",
    "# c4 = torch.full((27, 1), 1.0)\n",
    "\n",
    "# c = torch.cat((c1,c2,c3,c4), dim=1)\n",
    "# w1 = torch.full((EMB * BLOCK_SIZE, HIDDEN_LAYER_LENGTH))\n",
    "# b1 = torch.full((1,HIDDEN_LAYER_LENGTH))\n",
    "# w2 = torch.full((HIDDEN_LAYER_LENGTH, 27))\n",
    "# b2 = torch.full((1,27))\n",
    "\n",
    "parameters = [c, w1, b1, w2, b2]\n",
    "nparameters = sum(p.nelement() for p in parameters)\n",
    "print(f'{nparameters} parameters')\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "r = 10**-6\n",
    "e0 = 10**-2\n",
    "\n",
    "for i in range(EPOCHS + 1):\n",
    "    # minibatch construct\n",
    "    if i < int(0.95 * EPOCHS):\n",
    "        ix = torch.randint(0, Xtrain.shape[0], (BATCH_SIZE,))\n",
    "        emb = c[Xtrain[ix]]\n",
    "    else:\n",
    "        emb = c[Xtrain]\n",
    "    # forward pass\n",
    "    h = torch.tanh(emb.view(-1, EMB * BLOCK_SIZE) @ w1 + b1)\n",
    "    logits = h @ w2 + b2\n",
    "    if i < int(0.95 * EPOCHS):\n",
    "        loss = F.cross_entropy(logits, Ytrain[ix])\n",
    "    else:\n",
    "        loss = F.cross_entropy(logits, Ytrain)\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    lr = e0 * (1 + i*r) ** -1\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.data += -lr  * p.grad\n",
    "    # track stats\n",
    "\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "    if i%(EVAL_INTERVAL) == 0:\n",
    "        print(f\"Epochs: {i}\")       \n",
    "        print(f\"Train_loss: {loss.item():.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "plt.imshow(c.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "Xtrain[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "temp = c[Xtrain[3]]\n",
    "plt.imshow(temp.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "temp = temp.view(-1, 300)\n",
    "plt.imshow(temp.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "plt.imshow(w1.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "plt.imshow(b1.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "temp = temp @ w1 + b1\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.imshow(temp.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "temp = torch.tanh(temp)\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.imshow(temp.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "plt.imshow(w2.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "plt.imshow(b2.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "temp = temp @ w2 + b2\n",
    "\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.imshow(temp.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_moving_average = []\n",
    "\n",
    "window = 100\n",
    "for i in range(len(train_loss)- window + 1):\n",
    "    train_moving_average.append(np.mean(train_loss[i:i+window]))\n",
    "\n",
    "plt.plot(train_moving_average)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "print(min(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "results = generate_names(c, 100, BLOCK_SIZE, w1, b1, w2, b2, g)\n",
    "\n",
    "for result in results:\n",
    "    print(''.join(itos[i] for i in result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
